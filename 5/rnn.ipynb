{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a86537686dfd0405",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T17:37:00.538287Z",
     "start_time": "2024-11-27T17:36:58.753581Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n",
      "0\n",
      "<torch.cuda.device object at 0x70997658b160>\n",
      "Tesla V100-SXM3-32GB\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.current_device())\n",
    "print(torch.cuda.device(0))\n",
    "print(torch.cuda.get_device_name(0))\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed9f938c136cf55f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T17:38:36.640764Z",
     "start_time": "2024-11-27T17:37:00.568450Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# Load data\n",
    "questions = pd.read_csv('Questions.csv', encoding=\"latin-1\")\n",
    "tags = pd.read_csv('Tags.csv')\n",
    "\n",
    "# Merge questions and tags\n",
    "data = pd.merge(questions[['Id', 'Title', 'Body']], tags, left_on='Id', right_on='Id')\n",
    "\n",
    "\n",
    "def combine_title_and_body(row):\n",
    "    return row['Title'] + \" \" + row['Body']\n",
    "\n",
    "\n",
    "data['Text'] = data.apply(combine_title_and_body, axis=1)\n",
    "data.drop(['Title', 'Body'], axis=1, inplace=True)\n",
    "\n",
    "data = data[data['Tag'] != 'python']\n",
    "data = data[data['Tag'] != 'python-2.7']\n",
    "data = data[data['Tag'] != 'python-3.x']\n",
    "\n",
    "# Simplify: Use top N tags\n",
    "N = 15\n",
    "top_tags = data['Tag'].value_counts().nlargest(N).index\n",
    "data = data[data['Tag'].isin(top_tags)]\n",
    "\n",
    "data = data.groupby('Id').agg({\n",
    "    'Text': 'first',  # Retain unique Text for each question\n",
    "    'Tag': list  # Combine tags into a list\n",
    "}).reset_index()\n",
    "\n",
    "\n",
    "# Group tags by Id and select the most common tag\n",
    "def process_tags(tags):\n",
    "    if len(tags) > 1:\n",
    "        # Select the most common tag for multi-tag questions\n",
    "        tag_counts = pd.Series(tags).value_counts()\n",
    "        return tag_counts.idxmax()\n",
    "    return tags[0]  # Keep the single tag as is for single-tag questions\n",
    "\n",
    "\n",
    "data['Tag'] = data['Tag'].apply(process_tags)\n",
    "\n",
    "\n",
    "# Preprocess text\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'<.*?>', '', text)  # Remove HTML tags\n",
    "    text = re.sub(r'http\\S+|www\\S+|mailto:\\S+', '', text)\n",
    "    text = re.sub(r'<code>.*?</code>', '', text, flags=re.DOTALL)\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)  # Remove special characters\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Normalize spaces\n",
    "    text = text.lower().strip()  # Lowercase and strip\n",
    "    return text\n",
    "\n",
    "\n",
    "# Filter out empty titles after preprocessing\n",
    "data['Text'] = data['Text'].apply(preprocess_text)\n",
    "data = data[data['Text'].str.strip() != '']\n",
    "\n",
    "# Encode tags\n",
    "label_encoder = LabelEncoder()\n",
    "data['Tag'] = label_encoder.fit_transform(data['Tag'])\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['Text'], data['Tag'], test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "372b98a856826b4c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T19:40:53.216195Z",
     "start_time": "2024-11-27T19:40:48.602368Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    224563\n",
      "Name: Tag, dtype: int64\n",
      "Series([], Name: Tag, dtype: object)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Text</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>683</td>\n",
       "      <td>using in to match an attribute of python objec...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>742</td>\n",
       "      <td>class views in django django view points to a ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>766</td>\n",
       "      <td>python and mysql i can get python to work with...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1983</td>\n",
       "      <td>python what is the difference between 123 and ...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2933</td>\n",
       "      <td>how can i create a directlyexecutable crosspla...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Id                                               Text  Tag\n",
       "0   683  using in to match an attribute of python objec...    0\n",
       "1   742  class views in django django view points to a ...    3\n",
       "2   766  python and mysql i can get python to work with...    9\n",
       "3  1983  python what is the difference between 123 and ...    7\n",
       "4  2933  how can i create a directlyexecutable crosspla...   14"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group tags for each question\n",
    "grouped_tags = data.groupby('Id')['Tag'].apply(list)\n",
    "\n",
    "# Count questions with multiple tags\n",
    "print(grouped_tags.apply(len).value_counts())\n",
    "\n",
    "# Look at overlapping tags\n",
    "print(grouped_tags[grouped_tags.apply(len) > 1].head())\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d8eecfc5298ccee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T17:39:01.840230Z",
     "start_time": "2024-11-27T17:38:41.405754Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "from collections import Counter\n",
    "from torchtext.vocab import vocab\n",
    "\n",
    "# Tokenizer and vocabulary\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "counter = Counter()\n",
    "for sentence in X_train:\n",
    "    counter.update(tokenizer(sentence))\n",
    "\n",
    "vocab = vocab(counter, min_freq=1, specials=[\"<unk>\", \"<pad>\"])\n",
    "vocab_size = len(vocab)\n",
    "vocab.set_default_index(vocab[\"<unk>\"])\n",
    "\n",
    "\n",
    "# Function to convert text to tensor\n",
    "def text_to_tensor(text):\n",
    "    return torch.tensor([vocab[token] for token in tokenizer(text)], dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16065b7ff8836fe3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T17:39:01.923363Z",
     "start_time": "2024-11-27T17:39:01.916203Z"
    }
   },
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text_tensor = text_to_tensor(self.texts.iloc[idx])\n",
    "        label_tensor = torch.tensor(self.labels.iloc[idx], dtype=torch.long)\n",
    "        return text_tensor, label_tensor\n",
    "\n",
    "\n",
    "# Add a debug statement in the collate_fn function\n",
    "def collate_fn(batch):\n",
    "    texts, labels = zip(*batch)\n",
    "    lengths = [len(text) for text in texts]\n",
    "    if min(lengths) <= 0:\n",
    "        print(\"Found empty sequence in batch:\", lengths)\n",
    "    texts = torch.nn.utils.rnn.pad_sequence(texts, batch_first=True)\n",
    "    return texts, torch.tensor(labels), torch.tensor(lengths)\n",
    "\n",
    "\n",
    "# Datasets and DataLoaders\n",
    "train_dataset = TextDataset(X_train, y_train)\n",
    "test_dataset = TextDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bcef568523dc4541",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T17:39:01.971051Z",
     "start_time": "2024-11-27T17:39:01.964916Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class RNNClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, num_classes):\n",
    "        super(RNNClassifier, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.rnn = nn.LSTM(embed_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        x = self.embedding(x)\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(x, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        _, (hidden, _) = self.rnn(packed)\n",
    "        out = self.fc(hidden[-1])\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "212414a68c9cdf1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T17:39:06.110812Z",
     "start_time": "2024-11-27T17:39:02.013378Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "\n",
    "# Compute class weights\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(data['Tag']), y=data['Tag'])\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "\n",
    "# Model, Loss, Optimizer\n",
    "embed_size = 128\n",
    "hidden_size = 128\n",
    "num_classes = N  # Number of tags\n",
    "model = RNNClassifier(vocab_size, embed_size, hidden_size, num_classes).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0002)\n",
    "\n",
    "# Early stopping parameters\n",
    "patience = 3  # Number of epochs to wait before stopping\n",
    "best_val_loss = float('inf')\n",
    "patience_counter = 0\n",
    "\n",
    "# Training Loop with Early Stopping\n",
    "num_epochs = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79dd6b571c7681b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T18:35:41.469297Z",
     "start_time": "2024-11-27T17:39:06.201789Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/300], Train Loss: 2.4795, Val Loss: 2.2272\n",
      "Epoch [2/300], Train Loss: 2.1817, Val Loss: 2.2019\n",
      "Epoch [3/300], Train Loss: 2.0807, Val Loss: 2.1285\n",
      "Epoch [4/300], Train Loss: 1.9402, Val Loss: 2.1280\n",
      "Epoch [5/300], Train Loss: 1.9422, Val Loss: 1.9653\n",
      "Epoch [6/300], Train Loss: 1.5258, Val Loss: 1.4806\n",
      "Epoch [7/300], Train Loss: 0.9915, Val Loss: 1.0440\n",
      "Epoch [8/300], Train Loss: 0.7189, Val Loss: 0.7332\n",
      "Epoch [9/300], Train Loss: 0.5873, Val Loss: 0.6189\n",
      "Epoch [10/300], Train Loss: 0.5084, Val Loss: 0.6000\n",
      "Epoch [11/300], Train Loss: 0.4578, Val Loss: 0.5617\n",
      "Epoch [12/300], Train Loss: 0.4115, Val Loss: 0.5760\n",
      "Early stopping patience counter: 1/3\n",
      "Epoch [13/300], Train Loss: 0.3733, Val Loss: 0.6169\n",
      "Early stopping patience counter: 2/3\n",
      "Epoch [14/300], Train Loss: 0.3361, Val Loss: 0.6414\n",
      "Early stopping patience counter: 3/3\n",
      "Early stopping triggered. Stopping training.\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    # Training\n",
    "    for texts, labels, lengths in train_loader:\n",
    "        # Move tensors to GPU\n",
    "        texts, labels, lengths = texts.to(device), labels.to(device), lengths.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(texts, lengths)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for texts, labels, lengths in test_loader:\n",
    "            # Move tensors to GPU\n",
    "            texts, labels, lengths = texts.to(device), labels.to(device), lengths.to(device)\n",
    "            outputs = model(texts, lengths)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "    avg_val_loss = val_loss / len(test_loader)\n",
    "\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "    # Early Stopping\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        patience_counter = 0  # Reset counter\n",
    "\n",
    "        torch.save(model.state_dict(), \"best_model.pth\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        print(f\"Early stopping patience counter: {patience_counter}/{patience}\")\n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping triggered. Stopping training.\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8df46493757048d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T18:36:12.836066Z",
     "start_time": "2024-11-27T18:35:41.559282Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "           arrays       0.51      0.69      0.58      1823\n",
      "              csv       0.75      0.79      0.77      1622\n",
      "       dictionary       0.80      0.74      0.77      1822\n",
      "           django       0.98      0.88      0.93     12045\n",
      "            flask       0.84      0.92      0.87      1922\n",
      "google-app-engine       0.89      0.91      0.90      1839\n",
      "             json       0.73      0.82      0.77      1543\n",
      "             list       0.82      0.70      0.75      3174\n",
      "       matplotlib       0.84      0.89      0.86      2678\n",
      "            mysql       0.76      0.85      0.80      1486\n",
      "            numpy       0.60      0.65      0.62      3956\n",
      "           pandas       0.88      0.79      0.83      4367\n",
      "            regex       0.91      0.83      0.87      2795\n",
      "           string       0.53      0.78      0.63      1775\n",
      "          tkinter       0.96      0.87      0.91      2066\n",
      "\n",
      "         accuracy                           0.82     44913\n",
      "        macro avg       0.79      0.81      0.79     44913\n",
      "     weighted avg       0.83      0.82      0.82     44913\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "model.eval()\n",
    "all_preds, all_labels = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for texts, labels, lengths in test_loader:\n",
    "        # Move tensors to GPU\n",
    "        texts, labels, lengths = texts.to(device), labels.to(device), lengths.to(device)\n",
    "\n",
    "        outputs = model(texts, lengths)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "print(classification_report(all_labels, all_preds, target_names=label_encoder.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce84a921fbff5724",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T19:49:35.052428Z",
     "start_time": "2024-11-27T19:49:26.011354Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Tag: django\n",
      "Dialog with predicted tag: pythonsocialauth shows authstateforbidden sometimes sometimes when i try to login or register with facebook or google it returns me an error authstateforbidden screen but just refreshing the page or trying again after a while it run correctly ive tried adding google api in google developers but is the same problem with facebook any idea thanks in advance\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 30\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Take user input and categorize it\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m---> 30\u001b[0m     user_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEnter your question (or type \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mexit\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m to quit): \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m user_input\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexit\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     32\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py:1270\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1268\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1269\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[0;32m-> 1270\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1271\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1272\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1273\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1274\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py:1313\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1310\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1311\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[1;32m   1312\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1313\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1314\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1315\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F\n",
    "import random\n",
    "\n",
    "# Load the saved model\n",
    "model = RNNClassifier(vocab_size, embed_size, hidden_size, num_classes)  # Adjust with your model definition\n",
    "model.load_state_dict(torch.load(\"best_model.pth\"))\n",
    "model.eval()  # Set model to evaluation mode\n",
    "\n",
    "# Tokenize and pad the input\n",
    "def tokenize_and_prepare_input(text, tokenizer, vocab, max_length=100):\n",
    "    tokens = tokenizer(text)[:max_length]  # Tokenize and truncate to max_length\n",
    "    input_tensor = torch.tensor([vocab[token] if token in vocab else vocab['<unk>'] for token in tokens], dtype=torch.long)\n",
    "\n",
    "    # Calculate the sequence length\n",
    "    seq_length = len(input_tensor)\n",
    "\n",
    "    # Pad the sequence to max_length\n",
    "    if seq_length < max_length:\n",
    "        padding = torch.zeros(max_length - seq_length, dtype=torch.long)\n",
    "        input_tensor = torch.cat([input_tensor, padding])\n",
    "\n",
    "    input_tensor = input_tensor.unsqueeze(0)  # Add batch dimension\n",
    "    return input_tensor, torch.tensor([seq_length], dtype=torch.long)  # Return input tensor and sequence length\n",
    "\n",
    "tag_to_text = data.groupby('Tag')['Text'].apply(list).to_dict()\n",
    "\n",
    "# Take user input and categorize it\n",
    "while True:\n",
    "    user_input = input(\"Enter your question (or type 'exit' to quit): \")\n",
    "    if user_input.lower() == \"exit\":\n",
    "        break\n",
    "\n",
    "    # Prepare the input without removing any text\n",
    "    input_tensor, seq_length = tokenize_and_prepare_input(user_input, tokenizer, vocab)\n",
    "\n",
    "    # Predict the tag\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_tensor, seq_length)  # Pass lengths to the model\n",
    "        probabilities = F.softmax(outputs, dim=1)\n",
    "        predicted_class = torch.argmax(probabilities, dim=1).item()\n",
    "\n",
    "    if predicted_class in tag_to_text:\n",
    "        random_dialog = random.choice(tag_to_text[predicted_class])\n",
    "    else:\n",
    "        random_dialog = \"No examples available for this tag.\"\n",
    "\n",
    "    # Map the predicted class to the tag name\n",
    "    predicted_tag = label_encoder.inverse_transform([predicted_class])[0]\n",
    "\n",
    "    print(f\"Predicted Tag: {predicted_tag}\")\n",
    "    print(f\"Dialog with predicted tag: {random_dialog}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
