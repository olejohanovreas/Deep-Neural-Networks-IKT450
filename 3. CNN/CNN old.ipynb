{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T10:49:29.069766Z",
     "start_time": "2024-10-04T10:49:29.066474Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch import get_file_path\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b1bb0bc43be7e0d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T10:51:30.671632Z",
     "start_time": "2024-10-04T10:51:30.645554Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla V100-SXM3-32GB\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "343a53fc2025c95f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T10:49:29.153043Z",
     "start_time": "2024-10-04T10:49:29.149927Z"
    }
   },
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, img_dir, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_dir)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.img_dir[idx]\n",
    "        image = Image.open(img_path)\n",
    "\n",
    "        label = int(os.path.basename(img_path).split('_')[0])\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb89e649e0fb1fc0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T10:49:29.189384Z",
     "start_time": "2024-10-04T10:49:29.155045Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_file_paths(folder):\n",
    "    return [os.path.join(folder, fname) for fname in os.listdir(folder) if fname.endswith('.jpg')]\n",
    "\n",
    "\n",
    "train_data = get_file_paths('dataset/training')\n",
    "val_data = get_file_paths('dataset/validation')\n",
    "eval_data = get_file_paths('dataset/evaluation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5166bb154da02631",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T10:49:29.223725Z",
     "start_time": "2024-10-04T10:49:29.221105Z"
    }
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b96c740d7284fdc3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T10:49:29.259187Z",
     "start_time": "2024-10-04T10:49:29.255749Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = CustomImageDataset(train_data, transform=transform)\n",
    "val_dataset = CustomImageDataset(val_data, transform=transform)\n",
    "eval_dataset = CustomImageDataset(eval_data, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=True)\n",
    "eval_loader = DataLoader(eval_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c692fdd1768f7c58",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T10:49:29.297178Z",
     "start_time": "2024-10-04T10:49:29.291907Z"
    }
   },
   "outputs": [],
   "source": [
    "image, label = train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c431e941ce51939",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T10:49:29.332358Z",
     "start_time": "2024-10-04T10:49:29.328936Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 32, 32])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ff91300fe046f86",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T10:49:29.402921Z",
     "start_time": "2024-10-04T10:49:29.399964Z"
    }
   },
   "outputs": [],
   "source": [
    "class_names = ['Bread', 'Dairy product', 'Dessert', 'Egg', 'Fried food', 'Meat', 'Noodles/Pasta', 'Rice', 'Seafood', 'Soup', 'Vegetable/Fruit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6eb9281b-55de-4853-8f07-61a4edd02fd6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T10:49:29.411845Z",
     "start_time": "2024-10-04T10:49:29.406923Z"
    }
   },
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 12, 5)  # (12, 28, 28)\n",
    "        self.pool = nn.MaxPool2d(2, 2)  # (12, 14, 14)\n",
    "        self.conv2 = nn.Conv2d(12, 24, 4)  # (24, 10, 10) -> (24, 5, 5) -> Flatten (24 * 5 * 5)\n",
    "        self.fc1 = nn.Linear(24 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 11)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d86a654a9c6b322",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T10:49:29.450082Z",
     "start_time": "2024-10-04T10:49:29.445962Z"
    }
   },
   "outputs": [],
   "source": [
    "net = NeuralNet().to(device)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "539ee366715ea88b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T10:49:55.697105Z",
     "start_time": "2024-10-04T10:49:29.483927Z"
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 0...\n",
      "Loss: 2.3566\n",
      "Training epoch 1...\n",
      "Loss: 2.2670\n",
      "Training epoch 2...\n",
      "Loss: 2.2361\n",
      "Training epoch 3...\n",
      "Loss: 2.2086\n",
      "Training epoch 4...\n",
      "Loss: 2.1882\n",
      "Training epoch 5...\n",
      "Loss: 2.1681\n",
      "Training epoch 6...\n",
      "Loss: 2.1425\n",
      "Training epoch 7...\n",
      "Loss: 2.1108\n",
      "Training epoch 8...\n",
      "Loss: 2.0867\n",
      "Training epoch 9...\n",
      "Loss: 2.0651\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    print(f'Training epoch {epoch}...')\n",
    "\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for i, data in enumerate(train_loader):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs)\n",
    "\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f'Loss: {running_loss / len(train_loader):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b71dd6be7467024",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T10:49:55.734256Z",
     "start_time": "2024-10-04T10:49:55.729263Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), 'trained_nett.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "85b6bf47002eb78e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T10:49:55.772327Z",
     "start_time": "2024-10-04T10:49:55.766952Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = NeuralNet()\n",
    "net.load_state_dict(torch.load('trained_nett.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a26f1cdc7a24224c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T10:50:06.383246Z",
     "start_time": "2024-10-04T10:49:55.916148Z"
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m         _, predicted \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(outputs, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     11\u001b[0m         total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m         correct \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[43mpredicted\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     14\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m*\u001b[39m correct \u001b[38;5;241m/\u001b[39m total\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    for data in eval_loader:\n",
    "        images, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "\n",
    "print(f'Accuracy: {accuracy}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
