{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/olejohanjo/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available: True\n",
      "Amount of CUDA devices available: 1\n",
      "Index of current CUDA device: 0\n",
      "Name of current CUDA device: Tesla V100-SXM3-32GB\n",
      "Amount of CPU cores available: 96\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import random\n",
    "import shutil\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(f\"CUDA is available: {torch.cuda.is_available()}\")\n",
    "print(f\"Amount of CUDA devices available: {torch.cuda.device_count()}\")\n",
    "print(f\"Index of current CUDA device: {torch.cuda.current_device()}\")\n",
    "print(f\"Name of current CUDA device: {torch.cuda.get_device_name(torch.cuda.current_device())}\")\n",
    "print(f\"Amount of CPU cores available: {os.cpu_count()}\")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "cores = os.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45a19f075f739ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory 'dataset_with_paired_images' has been removed successfully.\n",
      "Date stamped: dataset_with_paired_images/stamped/training/2_394.jpg\n",
      "Date stamped: dataset_with_paired_images/stamped/training/9_321.jpg\n",
      "Date stamped: dataset_with_paired_images/stamped/training/7_107.jpg\n",
      "Date stamped: dataset_with_paired_images/stamped/training/1_84.jpg\n",
      "Date stamped: dataset_with_paired_images/stamped/training/9_386.jpg\n",
      "Date stamped: dataset_with_paired_images/stamped/training/9_1018.jpg\n",
      "Date stamped: dataset_with_paired_images/stamped/training/5_641.jpg\n",
      "Date stamped: dataset_with_paired_images/stamped/training/1_139.jpg\n",
      "Date stamped: dataset_with_paired_images/stamped/training/0_138.jpg\n",
      "Date stamped: dataset_with_paired_images/stamped/training/8_680.jpg\n",
      "Date stamped: dataset_with_paired_images/stamped/training/10_318.jpg\n",
      "Date stamped: dataset_with_paired_images/stamped/training/9_555.jpg\n",
      "Date stamped: dataset_with_paired_images/stamped/training/2_1186.jpg\n",
      "Date stamped: dataset_with_paired_images/stamped/training/9_611.jpg\n",
      "Date stamped: dataset_with_paired_images/stamped/training/6_80.jpg\n",
      "Date stamped: dataset_with_paired_images/stamped/training/8_536.jpg\n",
      "Date stamped: dataset_with_paired_images/stamped/training/0_779.jpg\n",
      "Date stamped: dataset_with_paired_images/stamped/training/6_45.jpg\n",
      "Date stamped: dataset_with_paired_images/stamped/training/9_173.jpg\n",
      "Date stamped: dataset_with_paired_images/stamped/training/3_718.jpg\n",
      "Date stamped: dataset_with_paired_images/stamped/validation/2_394.jpg\n",
      "Date stamped: dataset_with_paired_images/stamped/validation/2_297.jpg\n",
      "Date stamped: dataset_with_paired_images/stamped/validation/10_14.jpg\n",
      "Date stamped: dataset_with_paired_images/stamped/validation/0_165.jpg\n",
      "Date stamped: dataset_with_paired_images/stamped/validation/9_151.jpg\n",
      "Date stamped: dataset_with_paired_images/stamped/validation/5_188.jpg\n",
      "Date stamped: dataset_with_paired_images/stamped/validation/10_48.jpg\n",
      "Date stamped: dataset_with_paired_images/stamped/evaluation/2_394.jpg\n",
      "Date stamped: dataset_with_paired_images/stamped/evaluation/5_8.jpg\n",
      "Date stamped: dataset_with_paired_images/stamped/evaluation/4_245.jpg\n",
      "Date stamped: dataset_with_paired_images/stamped/evaluation/0_167.jpg\n",
      "Date stamped: dataset_with_paired_images/stamped/evaluation/5_431.jpg\n",
      "Date stamped: dataset_with_paired_images/stamped/evaluation/8_271.jpg\n",
      "Date stamped: dataset_with_paired_images/stamped/evaluation/8_133.jpg\n",
      "Paired dataset created at 'dataset_with_paired_images'\n"
     ]
    }
   ],
   "source": [
    "def add_date_stamp_to_images(input_dir, output_dir):\n",
    "    try:\n",
    "        shutil.rmtree(output_dir)\n",
    "        print(f\"Directory '{output_dir}' has been removed successfully.\")\n",
    "    except OSError as error:\n",
    "        print(error)\n",
    "\n",
    "    # Create directories for clean and noisy (stamped) images\n",
    "    clean_dir = os.path.join(output_dir, \"clean\")\n",
    "    stamped_dir = os.path.join(output_dir, \"stamped\")\n",
    "    os.makedirs(clean_dir, exist_ok=True)\n",
    "    os.makedirs(stamped_dir, exist_ok=True)\n",
    "\n",
    "    for subdir in ['training', 'validation', 'evaluation']:\n",
    "        input_subdir = os.path.join(input_dir, subdir)\n",
    "        clean_subdir = os.path.join(clean_dir, subdir)\n",
    "        stamped_subdir = os.path.join(stamped_dir, subdir)\n",
    "        os.makedirs(clean_subdir, exist_ok=True)\n",
    "        os.makedirs(stamped_subdir, exist_ok=True)\n",
    "\n",
    "        i = 0\n",
    "\n",
    "        for image_name in os.listdir(input_subdir):\n",
    "            if i >= 1025:\n",
    "                break\n",
    "                # break or pass to limit or not\n",
    "\n",
    "            # Load image\n",
    "            image_path = os.path.join(input_subdir, image_name)\n",
    "            image = Image.open(image_path)\n",
    "\n",
    "            # Save clean version\n",
    "            clean_output_path = os.path.join(clean_subdir, image_name)\n",
    "            image.save(clean_output_path)\n",
    "\n",
    "            # Add date stamp to a copy\n",
    "            draw = ImageDraw.Draw(image)\n",
    "            date_text = f\"{random.choice(months)} {random.randint(1, 28)}, 2024\"\n",
    "            font = ImageFont.load_default(32)  # Use default font\n",
    "            text_width = draw.textlength(date_text, font=font)\n",
    "            x, y = image.width - text_width - 10, image.height - 50\n",
    "            draw.text((x, y), date_text, fill=\"white\", font=font)\n",
    "\n",
    "            # Save stamped version\n",
    "            stamped_output_path = os.path.join(stamped_subdir, image_name)\n",
    "            image.save(stamped_output_path)\n",
    "\n",
    "            if i % 500 == 0:\n",
    "                print(f\"Date stamped: {stamped_output_path}\")\n",
    "            i += 1\n",
    "\n",
    "    print(f\"Paired dataset created at '{output_dir}'\")\n",
    "\n",
    "\n",
    "months = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November',\n",
    "          'December']\n",
    "\n",
    "add_date_stamp_to_images(\"dataset\", \"dataset_with_paired_images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218991a8f04c492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files in dataset_with_paired_images/stamped/: 16643\n",
      "Total files in dataset_with_paired_images/clean/: 16643\n",
      "Loaded 1000 stamped images into memory.\n",
      "Loaded 2000 stamped images into memory.\n",
      "Loaded 3000 stamped images into memory.\n",
      "Loaded 4000 stamped images into memory.\n",
      "Loaded 5000 stamped images into memory.\n",
      "Loaded 6000 stamped images into memory.\n",
      "Loaded 7000 stamped images into memory.\n",
      "Loaded 8000 stamped images into memory.\n",
      "Loaded 9000 stamped images into memory.\n",
      "Loaded 1000 clean images into memory.\n",
      "Loaded 2000 clean images into memory.\n",
      "Loaded 3000 clean images into memory.\n",
      "Loaded 4000 clean images into memory.\n",
      "Loaded 5000 clean images into memory.\n",
      "Loaded 6000 clean images into memory.\n",
      "Loaded 7000 clean images into memory.\n",
      "Loaded 8000 clean images into memory.\n",
      "Loaded 9000 clean images into memory.\n",
      "Total files in dataset_with_paired_images/stamped/: 16643\n",
      "Total files in dataset_with_paired_images/clean/: 16643\n",
      "Loaded 1000 stamped images into memory.\n",
      "Loaded 2000 stamped images into memory.\n",
      "Loaded 3000 stamped images into memory.\n",
      "Loaded 1000 clean images into memory.\n",
      "Loaded 2000 clean images into memory.\n",
      "Loaded 3000 clean images into memory.\n",
      "Total files in dataset_with_paired_images/stamped/: 16643\n",
      "Total files in dataset_with_paired_images/clean/: 16643\n",
      "Loaded 1000 stamped images into memory.\n",
      "Loaded 2000 stamped images into memory.\n",
      "Loaded 3000 stamped images into memory.\n",
      "Loaded 1000 clean images into memory.\n",
      "Loaded 2000 clean images into memory.\n"
     ]
    }
   ],
   "source": [
    "class PreloadedDateStampedDataset(Dataset):\n",
    "    def __init__(self, stamped_dir, clean_dir, transform):\n",
    "\n",
    "        self.stamped_images = []\n",
    "        self.clean_images = []\n",
    "\n",
    "        file_count = sum([len(files) for _, _, files in os.walk(\"dataset_with_paired_images/stamped/\")])\n",
    "        print(f\"Total files in dataset_with_paired_images/stamped/: {file_count}\")\n",
    "\n",
    "        file_count = sum([len(files) for _, _, files in os.walk(\"dataset_with_paired_images/clean/\")])\n",
    "        print(f\"Total files in dataset_with_paired_images/clean/: {file_count}\")\n",
    "\n",
    "        i = 0\n",
    "\n",
    "        # Apply transformations and load stamped images\n",
    "        for stamped_file in sorted(os.listdir(stamped_dir)):\n",
    "            stamped_path = os.path.join(stamped_dir, stamped_file)\n",
    "            stamped_image = Image.open(stamped_path).convert(\"RGB\")\n",
    "            if transform:\n",
    "                stamped_image = transform(stamped_image)\n",
    "            self.stamped_images.append(stamped_image)\n",
    "            i += 1\n",
    "            if i % 1000 == 0:\n",
    "                print(f\"Loaded {i} stamped images into memory.\")\n",
    "\n",
    "        i = 0\n",
    "        # Apply transformations and load clean images\n",
    "        for clean_file in sorted(os.listdir(clean_dir)):\n",
    "            clean_path = os.path.join(clean_dir, clean_file)\n",
    "            clean_image = Image.open(clean_path).convert(\"RGB\")\n",
    "            if transform:\n",
    "                clean_image = transform(clean_image)\n",
    "            self.clean_images.append(clean_image)\n",
    "            i += 1\n",
    "            if i % 1000 == 0:\n",
    "                print(f\"Loaded {i} clean images into memory.\")\n",
    "\n",
    "        # Ensure equal number of stamped and clean images\n",
    "        assert len(self.stamped_images) == len(self.clean_images), \"Mismatch in paired dataset size\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.stamped_images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Preprocessed images are already in memory\n",
    "        stamped_image = self.stamped_images[idx]\n",
    "        clean_image = self.clean_images[idx]\n",
    "        return stamped_image, clean_image\n",
    "\n",
    "\n",
    "# Transformations for input images\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((448, 448)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Initialize DataLoaders\n",
    "train_loader = DataLoader(\n",
    "    PreloadedDateStampedDataset(\n",
    "        stamped_dir='dataset_with_paired_images/stamped/training',\n",
    "        clean_dir='dataset_with_paired_images/clean/training',\n",
    "        transform=transform\n",
    "    ),\n",
    "    batch_size=256, shuffle=True, num_workers=0, pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    PreloadedDateStampedDataset(\n",
    "        stamped_dir='dataset_with_paired_images/stamped/validation',\n",
    "        clean_dir='dataset_with_paired_images/clean/validation',\n",
    "        transform=transform\n",
    "    ),\n",
    "    batch_size=256, shuffle=False, num_workers=0, pin_memory=True\n",
    ")\n",
    "\n",
    "eval_loader = DataLoader(\n",
    "    PreloadedDateStampedDataset(\n",
    "        stamped_dir='dataset_with_paired_images/stamped/evaluation',\n",
    "        clean_dir='dataset_with_paired_images/clean/evaluation',\n",
    "        transform=transform\n",
    "    ),\n",
    "    batch_size=256, shuffle=False, num_workers=0, pin_memory=True\n",
    ")\n",
    "\n",
    "for stamped_batch, clean_batch in train_loader:\n",
    "    print(stamped_batch.shape, clean_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a99f0c6b98abf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=4, stride=2, padding=1),  # 512x512 -> 256x256\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),  # 256x256 -> 128x128\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1),  # 128x128 -> 64x64\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),  # 64x64 -> 128x128\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),  # 128x128 -> 256x256\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 3, kernel_size=4, stride=2, padding=1),  # 256x256 -> 512x512\n",
    "            nn.Sigmoid(),  # Output in range [0, 1]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "\n",
    "# Initialize Autoencoder\n",
    "autoencoder = Autoencoder().to(device, non_blocking=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55db519aec4e75aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(autoencoder.parameters(), lr=0.001)\n",
    "\n",
    "patience = 2\n",
    "best_val_loss = np.inf\n",
    "early_stop_counter = 0\n",
    "num_epochs = 300\n",
    "\n",
    "scaler = GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf911863416e41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    autoencoder.train()\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for stamped_images, clean_images in train_loader:\n",
    "        stamped_images, clean_images = stamped_images.to(device, non_blocking=True), clean_images.to(device, non_blocking=True)\n",
    "\n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        with autocast():\n",
    "            outputs = autoencoder(stamped_images)\n",
    "            loss = criterion(outputs, clean_images)  # Compute loss against clean images\n",
    "\n",
    "        # Scale loss for FP16 stability\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "\n",
    "    # Validation phase\n",
    "    autoencoder.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for stamped_images, clean_images in val_loader:\n",
    "            # Move data to device\n",
    "            stamped_images, clean_images = stamped_images.to(device, non_blocking=True), clean_images.to(device, non_blocking=True)\n",
    "\n",
    "            outputs = autoencoder(stamped_images)\n",
    "            loss = criterion(outputs, clean_images)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Train Loss: {avg_train_loss:.6f}, Val Loss: {avg_val_loss:.6f}\")\n",
    "\n",
    "    # Early stopping check\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        early_stop_counter = 0\n",
    "\n",
    "        # Save the best model\n",
    "        torch.save(autoencoder.state_dict(), \"good_autoencoder.pth\")\n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "        print(f\"Early stopping patience counter: {early_stop_counter}/{patience}\")\n",
    "        if early_stop_counter >= patience:\n",
    "            print(\"Early stopping triggered!\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7246740257c50fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(input_images, reconstructed, n=4):\n",
    "    plt.figure(figsize=(12, 4))  # Adjusted figure size to reduce spacing\n",
    "    for i in range(n):\n",
    "        # Stamped (Input) images\n",
    "        plt.subplot(2, n, i + 1)\n",
    "        input_img = input_images[i].permute(1, 2, 0).cpu().numpy()  # CHW -> HWC\n",
    "        input_img = np.clip(input_img, 0, 1)  # Ensure pixel values are in [0, 1]\n",
    "        plt.imshow(input_img)\n",
    "        plt.axis('off')\n",
    "        plt.title(\"Stamped (Input)\")\n",
    "\n",
    "        # Reconstructed (Output) images\n",
    "        plt.subplot(2, n, i + 1 + n)\n",
    "        reconstructed_img = reconstructed[i].permute(1, 2, 0).cpu().numpy()  # CHW -> HWC\n",
    "        reconstructed_img = np.clip(reconstructed_img, 0, 1)  # Ensure pixel values are in [0, 1]\n",
    "        plt.imshow(reconstructed_img)\n",
    "        plt.axis('off')\n",
    "        plt.title(\"Reconstructed (Output)\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Evaluate on the evaluation dataset\n",
    "stamped_images, reconstructed_images = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for stamped, clean in eval_loader:\n",
    "        stamped = stamped.to(device, non_blocking=True)\n",
    "        outputs = autoencoder(stamped)\n",
    "        stamped_images.extend(stamped.cpu())\n",
    "        reconstructed_images.extend(outputs.cpu())\n",
    "        if len(stamped_images) >= 4:  # Limit to 4 examples\n",
    "            break\n",
    "\n",
    "# Visualize\n",
    "show_images(stamped_images, reconstructed_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759719f03164488e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
