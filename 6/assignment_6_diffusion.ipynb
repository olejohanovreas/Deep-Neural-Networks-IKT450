{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T11:51:55.096613Z",
     "start_time": "2024-11-27T11:51:52.464727Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available: True\n",
      "Amount of CUDA devices available: 1\n",
      "Index of current CUDA device: 0\n",
      "Name of current CUDA device: Tesla V100-SXM3-32GB\n",
      "Amount of CPU cores available: 96\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import random\n",
    "import shutil\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(f\"CUDA is available: {torch.cuda.is_available()}\")\n",
    "print(f\"Amount of CUDA devices available: {torch.cuda.device_count()}\")\n",
    "print(f\"Index of current CUDA device: {torch.cuda.current_device()}\")\n",
    "print(f\"Name of current CUDA device: {torch.cuda.get_device_name(torch.cuda.current_device())}\")\n",
    "print(f\"Amount of CPU cores available: {os.cpu_count()}\")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "cores = os.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6855c6073a353c01",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T11:52:13.888435Z",
     "start_time": "2024-11-27T11:51:55.232531Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory 'dataset_with_paired_images' has been removed successfully.\n",
      "Date stamped: dataset_with_paired_images/stamped/training/2_394.jpg\n",
      "Date stamped: dataset_with_paired_images/stamped/validation/2_394.jpg\n",
      "Date stamped: dataset_with_paired_images/stamped/evaluation/2_394.jpg\n",
      "Paired dataset created at 'dataset_with_paired_images'\n"
     ]
    }
   ],
   "source": [
    "def add_date_stamp_to_images(input_dir, output_dir):\n",
    "    try:\n",
    "        shutil.rmtree(output_dir)\n",
    "        print(f\"Directory '{output_dir}' has been removed successfully.\")\n",
    "    except OSError as error:\n",
    "        print(error)\n",
    "\n",
    "    # Create directories for clean and noisy (stamped) images\n",
    "    clean_dir = os.path.join(output_dir, \"clean\")\n",
    "    stamped_dir = os.path.join(output_dir, \"stamped\")\n",
    "    os.makedirs(clean_dir, exist_ok=True)\n",
    "    os.makedirs(stamped_dir, exist_ok=True)\n",
    "\n",
    "    for subdir in ['training', 'validation', 'evaluation']:\n",
    "        input_subdir = os.path.join(input_dir, subdir)\n",
    "        clean_subdir = os.path.join(clean_dir, subdir)\n",
    "        stamped_subdir = os.path.join(stamped_dir, subdir)\n",
    "        os.makedirs(clean_subdir, exist_ok=True)\n",
    "        os.makedirs(stamped_subdir, exist_ok=True)\n",
    "\n",
    "        i = 0\n",
    "\n",
    "        for image_name in os.listdir(input_subdir):\n",
    "            if i >= 10:\n",
    "                break\n",
    "                # break or pass to limit or not\n",
    "\n",
    "            # Load image\n",
    "            image_path = os.path.join(input_subdir, image_name)\n",
    "            image = Image.open(image_path)\n",
    "\n",
    "            # Save clean version\n",
    "            clean_output_path = os.path.join(clean_subdir, image_name)\n",
    "            image.save(clean_output_path)\n",
    "\n",
    "            # Add date stamp to a copy\n",
    "            draw = ImageDraw.Draw(image)\n",
    "            date_text = f\"{random.choice(months)} {random.randint(1, 28)}, 2024\"\n",
    "            font = ImageFont.load_default(32)  # Use default font\n",
    "            text_width = draw.textlength(date_text, font=font)\n",
    "            x, y = image.width - text_width - 10, image.height - 50\n",
    "            draw.text((x, y), date_text, fill=\"white\", font=font)\n",
    "\n",
    "            # Save stamped version\n",
    "            stamped_output_path = os.path.join(stamped_subdir, image_name)\n",
    "            image.save(stamped_output_path)\n",
    "\n",
    "            if i % 500 == 0:\n",
    "                print(f\"Date stamped: {stamped_output_path}\")\n",
    "            i += 1\n",
    "\n",
    "    print(f\"Paired dataset created at '{output_dir}'\")\n",
    "\n",
    "\n",
    "months = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November',\n",
    "          'December']\n",
    "\n",
    "add_date_stamp_to_images(\"dataset\", \"dataset_with_paired_images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68bbaec27ae65a01",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T11:54:53.942178Z",
     "start_time": "2024-11-27T11:52:14.107108Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files in dataset_with_paired_images/stamped/: 30\n",
      "Total files in dataset_with_paired_images/clean/: 30\n",
      "Total files in dataset_with_paired_images/stamped/: 30\n",
      "Total files in dataset_with_paired_images/clean/: 30\n",
      "Total files in dataset_with_paired_images/stamped/: 30\n",
      "Total files in dataset_with_paired_images/clean/: 30\n",
      "torch.Size([4, 3, 448, 448]) torch.Size([4, 3, 448, 448])\n"
     ]
    }
   ],
   "source": [
    "class PreloadedDateStampedDataset(Dataset):\n",
    "    def __init__(self, stamped_dir, clean_dir, transform):\n",
    "\n",
    "        self.stamped_images = []\n",
    "        self.clean_images = []\n",
    "\n",
    "        file_count = sum([len(files) for _, _, files in os.walk(\"dataset_with_paired_images/stamped/\")])\n",
    "        print(f\"Total files in dataset_with_paired_images/stamped/: {file_count}\")\n",
    "\n",
    "        file_count = sum([len(files) for _, _, files in os.walk(\"dataset_with_paired_images/clean/\")])\n",
    "        print(f\"Total files in dataset_with_paired_images/clean/: {file_count}\")\n",
    "\n",
    "        i = 0\n",
    "\n",
    "        # Apply transformations and load stamped images\n",
    "        for stamped_file in sorted(os.listdir(stamped_dir)):\n",
    "            stamped_path = os.path.join(stamped_dir, stamped_file)\n",
    "            stamped_image = Image.open(stamped_path).convert(\"RGB\")\n",
    "            if transform:\n",
    "                stamped_image = transform(stamped_image)\n",
    "            self.stamped_images.append(stamped_image)\n",
    "            i += 1\n",
    "            if i % 1000 == 0:\n",
    "                print(f\"Loaded {i} stamped images into memory.\")\n",
    "\n",
    "        i = 0\n",
    "        # Apply transformations and load clean images\n",
    "        for clean_file in sorted(os.listdir(clean_dir)):\n",
    "            clean_path = os.path.join(clean_dir, clean_file)\n",
    "            clean_image = Image.open(clean_path).convert(\"RGB\")\n",
    "            if transform:\n",
    "                clean_image = transform(clean_image)\n",
    "            self.clean_images.append(clean_image)\n",
    "            i += 1\n",
    "            if i % 1000 == 0:\n",
    "                print(f\"Loaded {i} clean images into memory.\")\n",
    "\n",
    "        # Ensure equal number of stamped and clean images\n",
    "        assert len(self.stamped_images) == len(self.clean_images), \"Mismatch in paired dataset size\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.stamped_images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Preprocessed images are already in memory\n",
    "        stamped_image = self.stamped_images[idx]\n",
    "        clean_image = self.clean_images[idx]\n",
    "        return stamped_image, clean_image\n",
    "\n",
    "\n",
    "# Transformations for input images\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((448, 448)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),  # Normalize to [-1, 1]\n",
    "])\n",
    "\n",
    "# Initialize DataLoaders\n",
    "train_loader = DataLoader(\n",
    "    PreloadedDateStampedDataset(\n",
    "        stamped_dir='dataset_with_paired_images/stamped/training',\n",
    "        clean_dir='dataset_with_paired_images/clean/training',\n",
    "        transform=transform\n",
    "    ),\n",
    "    batch_size=4, shuffle=True, num_workers=0, pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    PreloadedDateStampedDataset(\n",
    "        stamped_dir='dataset_with_paired_images/stamped/validation',\n",
    "        clean_dir='dataset_with_paired_images/clean/validation',\n",
    "        transform=transform\n",
    "    ),\n",
    "    batch_size=4, shuffle=False, num_workers=0, pin_memory=True\n",
    ")\n",
    "\n",
    "eval_loader = DataLoader(\n",
    "    PreloadedDateStampedDataset(\n",
    "        stamped_dir='dataset_with_paired_images/stamped/evaluation',\n",
    "        clean_dir='dataset_with_paired_images/clean/evaluation',\n",
    "        transform=transform\n",
    "    ),\n",
    "    batch_size=4, shuffle=False, num_workers=0, pin_memory=True\n",
    ")\n",
    "\n",
    "for stamped_batch, clean_batch in train_loader:\n",
    "    print(stamped_batch.shape, clean_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef1deee748f28845",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T11:54:54.064961Z",
     "start_time": "2024-11-27T11:54:54.059129Z"
    }
   },
   "outputs": [],
   "source": [
    "class Diffusion:\n",
    "    def __init__(self, num_steps=1000, beta_start=1e-4, beta_end=0.02):\n",
    "        self.num_steps = num_steps\n",
    "        self.beta_start = beta_start\n",
    "        self.beta_end = beta_end\n",
    "\n",
    "        self.betas = torch.linspace(beta_start, beta_end, num_steps).to(device)\n",
    "        self.alphas = 1.0 - self.betas\n",
    "        self.alpha_bar = torch.cumprod(self.alphas, dim=0)\n",
    "\n",
    "    def forward_process(self, x0, t):\n",
    "        noise = torch.randn_like(x0).to(device)\n",
    "        sqrt_alpha_bar_t = torch.sqrt(self.alpha_bar[t])[:, None, None, None]\n",
    "        sqrt_one_minus_alpha_bar_t = torch.sqrt(1 - self.alpha_bar[t])[:, None, None, None]\n",
    "        xt = sqrt_alpha_bar_t * x0 + sqrt_one_minus_alpha_bar_t * noise\n",
    "        return xt, noise\n",
    "\n",
    "    def reverse_process(self, model, xt, t):\n",
    "        pred_noise = model(xt, t)\n",
    "        sqrt_alpha_bar_t = torch.sqrt(self.alpha_bar[t])[:, None, None, None]\n",
    "        sqrt_one_minus_alpha_bar_t = torch.sqrt(1 - self.alpha_bar[t])[:, None, None, None]\n",
    "        x0_pred = (xt - sqrt_one_minus_alpha_bar_t * pred_noise) / sqrt_alpha_bar_t\n",
    "        return x0_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "edd8e304b9c78da6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T11:54:54.125224Z",
     "start_time": "2024-11-27T11:54:54.119548Z"
    }
   },
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self, num_channels=3):\n",
    "        super(UNet, self).__init__()\n",
    "        self.encoder1 = self.conv_block(num_channels, 64)\n",
    "        self.encoder2 = self.conv_block(64, 128)\n",
    "        self.encoder3 = self.conv_block(128, 256)\n",
    "        self.encoder4 = self.conv_block(256, 512)\n",
    "        self.middle = self.conv_block(512, 512)\n",
    "        self.decoder4 = self.conv_block(512, 256)\n",
    "        self.decoder3 = self.conv_block(256, 128)\n",
    "        self.decoder2 = self.conv_block(128, 64)\n",
    "        self.decoder1 = nn.Conv2d(64, num_channels, kernel_size=3, padding=1)\n",
    "\n",
    "    def conv_block(self, in_channels, out_channels):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        e1 = self.encoder1(x)\n",
    "        e2 = self.encoder2(e1)\n",
    "        e3 = self.encoder3(e2)\n",
    "        e4 = self.encoder4(e3)\n",
    "        m = self.middle(e4)\n",
    "        d4 = self.decoder4(m + e4)\n",
    "        d3 = self.decoder3(d4 + e3)\n",
    "        d2 = self.decoder2(d3 + e2)\n",
    "        d1 = self.decoder1(d2 + e1)\n",
    "        return d1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15a8dcd9-fff4-4f8e-b28d-819609f13d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize diffusion process and model\n",
    "diffusion = Diffusion(num_steps=200)\n",
    "model = UNet(num_channels=3).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# Gradient scaler for mixed precision\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "# Early stopping parameters\n",
    "patience = 5  # Number of epochs to wait for improvement\n",
    "best_val_loss = float(\"inf\")\n",
    "early_stop_counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0ce2905d95de8a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T12:18:40.066031Z",
     "start_time": "2024-11-27T12:14:30.021098Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50] - Train Loss: 0.3645, Val Loss: 0.1571\n",
      "Validation loss improved. Model saved.\n",
      "Epoch [2/50] - Train Loss: 0.1108, Val Loss: 0.0919\n",
      "Validation loss improved. Model saved.\n",
      "Epoch [3/50] - Train Loss: 0.0802, Val Loss: 0.0791\n",
      "Validation loss improved. Model saved.\n",
      "Epoch [4/50] - Train Loss: 0.0753, Val Loss: 0.0663\n",
      "Validation loss improved. Model saved.\n",
      "Epoch [5/50] - Train Loss: 0.0627, Val Loss: 0.0556\n",
      "Validation loss improved. Model saved.\n",
      "Epoch [6/50] - Train Loss: 0.0566, Val Loss: 0.0886\n",
      "Early stopping counter: 1/5\n",
      "Epoch [7/50] - Train Loss: 0.0581, Val Loss: 0.0583\n",
      "Early stopping counter: 2/5\n",
      "Epoch [8/50] - Train Loss: 0.0498, Val Loss: 0.0473\n",
      "Validation loss improved. Model saved.\n",
      "Epoch [9/50] - Train Loss: 0.0528, Val Loss: 0.0481\n",
      "Early stopping counter: 1/5\n",
      "Epoch [10/50] - Train Loss: 0.0425, Val Loss: 0.0469\n",
      "Validation loss improved. Model saved.\n",
      "Epoch [11/50] - Train Loss: 0.0456, Val Loss: 0.0448\n",
      "Validation loss improved. Model saved.\n",
      "Epoch [12/50] - Train Loss: 0.0495, Val Loss: 0.0437\n",
      "Validation loss improved. Model saved.\n",
      "Epoch [13/50] - Train Loss: 0.0420, Val Loss: 0.0395\n",
      "Validation loss improved. Model saved.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for stamped_images, clean_images in train_loader:\n",
    "        stamped_images, clean_images = stamped_images.to(device), clean_images.to(device)\n",
    "\n",
    "        # Sample random timesteps\n",
    "        t = torch.randint(0, diffusion.num_steps, (stamped_images.size(0),)).to(device)\n",
    "\n",
    "        # Forward process: add noise\n",
    "        xt, noise = diffusion.forward_process(clean_images, t)\n",
    "\n",
    "        # Mixed precision forward pass\n",
    "        optimizer.zero_grad()\n",
    "        with torch.cuda.amp.autocast():\n",
    "            pred_noise = model(xt, t)  # Predict noise\n",
    "            loss = nn.MSELoss()(pred_noise, noise)  # Compute loss\n",
    "\n",
    "        # Backpropagation with mixed precision\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    train_loss = epoch_loss / len(train_loader)\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for stamped_images, clean_images in val_loader:\n",
    "            stamped_images, clean_images = stamped_images.to(device), clean_images.to(device)\n",
    "\n",
    "            # Sample random timesteps\n",
    "            t = torch.randint(0, diffusion.num_steps, (stamped_images.size(0),)).to(device)\n",
    "\n",
    "            # Forward process: add noise\n",
    "            xt, noise = diffusion.forward_process(clean_images, t)\n",
    "\n",
    "            # Mixed precision forward pass\n",
    "            with torch.cuda.amp.autocast():\n",
    "                pred_noise = model(xt, t)  # Predict noise\n",
    "                loss = nn.MSELoss()(pred_noise, noise)  # Compute loss\n",
    "                val_loss += loss.item()\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}] - Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "    # Early stopping check\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        early_stop_counter = 0\n",
    "\n",
    "        # Save the best model\n",
    "        torch.save(model.state_dict(), \"best_diffusion_model.pth\")\n",
    "        print(f\"Validation loss improved. Model saved.\")\n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "        print(f\"Early stopping counter: {early_stop_counter}/{patience}\")\n",
    "\n",
    "        if early_stop_counter >= patience:\n",
    "            print(\"Early stopping triggered. Training stopped.\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1e098d3546f0f43",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 30\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m stamped_images, clean_images \u001b[38;5;129;01min\u001b[39;00m val_loader:\n\u001b[1;32m     29\u001b[0m     stamped_images \u001b[38;5;241m=\u001b[39m stamped_images\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 30\u001b[0m     xt, _ \u001b[38;5;241m=\u001b[39m \u001b[43mdiffusion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_process\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstamped_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m999\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t_step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m999\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     32\u001b[0m         xt \u001b[38;5;241m=\u001b[39m diffusion\u001b[38;5;241m.\u001b[39mreverse_process(model, xt, torch\u001b[38;5;241m.\u001b[39mtensor([t_step])\u001b[38;5;241m.\u001b[39mto(device))\n",
      "Cell \u001b[0;32mIn[12], line 13\u001b[0m, in \u001b[0;36mDiffusion.forward_process\u001b[0;34m(self, x0, t)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward_process\u001b[39m(\u001b[38;5;28mself\u001b[39m, x0, t):\n\u001b[1;32m     12\u001b[0m     noise \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn_like(x0)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 13\u001b[0m     sqrt_alpha_bar_t \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malpha_bar\u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m[:, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[1;32m     14\u001b[0m     sqrt_one_minus_alpha_bar_t \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malpha_bar[t])[:, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[1;32m     15\u001b[0m     xt \u001b[38;5;241m=\u001b[39m sqrt_alpha_bar_t \u001b[38;5;241m*\u001b[39m x0 \u001b[38;5;241m+\u001b[39m sqrt_one_minus_alpha_bar_t \u001b[38;5;241m*\u001b[39m noise\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/pytorch/pytorch/aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [0,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n"
     ]
    }
   ],
   "source": [
    "# Load the trained model\n",
    "model.load_state_dict(torch.load(\"best_diffusion_model.pth\", map_location=device))\n",
    "\n",
    "\n",
    "def show_images(input_images, reconstructed, n=4):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    for i in range(n):\n",
    "        plt.subplot(2, n, i + 1)\n",
    "        input_img = input_images[i].permute(1, 2, 0).cpu().numpy()\n",
    "        input_img = (input_img + 1) / 2\n",
    "        plt.imshow(np.clip(input_img, 0, 1))\n",
    "        plt.axis('off')\n",
    "        plt.title(\"Stamped (Input)\")\n",
    "#\n",
    "        plt.subplot(2, n, i + 1 + n)\n",
    "        reconstructed_img = reconstructed[i].permute(1, 2, 0).cpu().numpy()\n",
    "        reconstructed_img = (reconstructed_img + 1) / 2\n",
    "        plt.imshow(np.clip(reconstructed_img, 0, 1))\n",
    "        plt.axis('off')\n",
    "        plt.title(\"Denoised (Output)\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Evaluate and visualize results\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for stamped_images, clean_images in val_loader:\n",
    "        stamped_images = stamped_images.to(device)\n",
    "        xt, _ = diffusion.forward_process(stamped_images, t=torch.tensor([999]).to(device))\n",
    "        for t_step in range(999, -1, -1):\n",
    "            xt = diffusion.reverse_process(model, xt, torch.tensor([t_step]).to(device))\n",
    "\n",
    "        show_images(stamped_images.cpu(), xt.cpu())\n",
    "        break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
